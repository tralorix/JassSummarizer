{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation 04\n",
    "\n",
    "I will prepare the data appropriately for the analysis and modeling (data cleaning, manipulation, feature engineering). I'm going to analyze image data from :\n",
    "* train_datascan_ii\n",
    "* train_datascan_iii\n",
    "* train_datascan_iv\n",
    "\n",
    "> NOTE: I will skip the data from datascan_i as there is no need for more data and on this dataset the background would need an other threshold setting to remove the wooden background.\n",
    "\n",
    "#### Datacleaning\n",
    "There was only a minor data cleaning step on datascan_iii. As the image extraction from the movie may also had some images where a card was only showed partitially, I did a visual check within the Windows explorer. As the frames are just in order of the time, it was a peace of cake to eliminate them. The cleaning step of my exported data was done in this manner.\n",
    "\n",
    "#### Feature Engineering\n",
    "\n",
    "The following data are beeing collected:\n",
    "* dataSet (internal use)\n",
    "* cardId (will be the target feature)\n",
    "* x (value of bounding box within original image)\n",
    "* y (value of bounding box within original image)\n",
    "* width (width of the image)\n",
    "* height (height of the image)\n",
    "* orgWidth (width of the original image)\n",
    "* orgHeight (width of the original image)\n",
    "* red channel histogram data from value r0 to r255\n",
    "* green channel histogram data from value g0 to g255\n",
    "* blue channel histogram data from value b0 to b255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                | 5/1154 [00:00<00:28, 40.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Name: datascan_ii     includes   1154 images on Path: .\\images\\02_data_preparation\\train_datascan_ii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1154/1154 [00:26<00:00, 43.29it/s]\n",
      "  0%|                                                                                | 5/13904 [00:00<05:47, 40.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Name: datascan_iii    includes  13904 images on Path: .\\images\\02_data_preparation\\train_datascan_iii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 13904/13904 [05:59<00:00, 38.63it/s]\n",
      "  0%|                                                                                 | 5/6480 [00:00<02:15, 47.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Name: datascan_iv     includes   6480 images on Path: .\\images\\02_data_preparation\\train_datascan_iv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 6480/6480 [02:28<00:00, 43.49it/s]\n"
     ]
    }
   ],
   "source": [
    "import JassSummarizer as js\n",
    "from IPython.core.display import display, HTML\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import os\n",
    "import cv2                                                                                  # computer vision python library see README.md dependencies\n",
    "                                                                                            # computer vision python library see README.md dependencies\n",
    "\n",
    "np.set_printoptions(suppress=True)                                      # do not use scientific notation for number in numpy\n",
    "pathList= [r\".\\images\\02_data_preparation\\train_datascan_ii\",r\".\\images\\02_data_preparation\\train_datascan_iii\",r\".\\images\\02_data_preparation\\train_datascan_iv\"]\n",
    "color = ('b','g','r')                                                   # the graph enumerator and color\n",
    "columnTitle=[]\n",
    "                                                                                            # computer vision python library see README.md dependencies\n",
    "columnTitle=columnTitle+\"dataSet,cardId,x,y,width,height,orgWidth,orgHeight\".split(\",\")     # title for the first part of columns\n",
    "columnTitle=columnTitle+\"\".join([f\"r{num},\" for num in range(256)]).split(\",\")[0:-1]        # adding all the red color numbered labels from r0-r255\n",
    "columnTitle=columnTitle+\"\".join([f\"g{num},\" for num in range(256)]).split(\",\")[0:-1]        # adding all the green color numbered labels from g0-g255\n",
    "columnTitle=columnTitle+\"\".join([f\"b{num},\" for num in range(256)]).split(\",\")[0:-1]        # adding all the blue color numbered labels from b0-b255\n",
    "data={}                                                                                     # dictionary to store the collected datas\n",
    "\n",
    "if 1==1:\n",
    " for path in pathList:\n",
    "    dataSet=path.split(\"\\\\\")[-1].replace(\"train_\",\"\")\n",
    "    fileList = [os.path.join(dp, f) for dp, dn, filenames in os.walk(path) for f in filenames if os.path.splitext(f)[1] == '.jpg']\n",
    "    print(f\"Dataset Name: {dataSet:15} includes {len(fileList):6} images on Path: {path}\")    \n",
    "    data[dataSet]=[]\n",
    "                                                                                            # computer vision python library see README.md dependencies    \n",
    "    with tqdm(total=len(fileList)) as pbar:                                                 # visualize progress\n",
    "        for file in fileList:                                                               # iterate trough all images in dataset\n",
    "            histr = []                                                                      # reset histogram recordset\n",
    "            img=cv2.imread(file,cv2.IMREAD_COLOR)                                           # read image\n",
    "            orgHeight,orgWidth = img.shape[0],img.shape[1]                                  # save original image dimensions\n",
    "            frameOrg,mask,img_rect,res,crop_img,d=js.analyzeScan(img)                       # analyze image data and receive droped image\n",
    "            x,y,width,height=d                                                              # store dimensions\n",
    "            for i,colorChannel in enumerate(color):                                         # color enumerator\n",
    "                histr.append(cv2.calcHist([crop_img],[i],None,[256],[0,256]))               # calc histodata\n",
    "            r=histr[2]; g=histr[1]; b=histr[0]                                              # prepare r,g,b column data\n",
    "            cardId=file.split(\"\\\\\")[-1][0:2]                                                # get cardId from filename\n",
    "            # concatenate all the collected data \n",
    "            data[dataSet].append(np.concatenate(([dataSet,cardId,x,y,width,height,orgWidth,orgHeight],r.flatten().astype(\"uint32\"),g.flatten().astype(\"uint32\"),b.flatten().astype(\"uint32\")),axis=0).flatten())\n",
    "            pbar.update(1)                                                                  # update visualization progress\n",
    "        df=pd.DataFrame(np.array(data[dataSet]),columns=columnTitle)                        # add numpy array to dataframe\n",
    "        df.to_csv(dataSet+\".csv\",header=True)                                               # save dataframe as csv including header infos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
